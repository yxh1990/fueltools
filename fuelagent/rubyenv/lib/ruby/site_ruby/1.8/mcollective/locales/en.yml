en:
  PLMC1:
    example: "The Marionette Collective version 2.2.2 started by /usr/bin/mco using config file /etc/mcollective/client.cfg"
    expanded: "This message gets logged each time MCollective reads it's config file.  Generally this only happens once per process.  It shows the version, process name and config file as a simple debugging aid"
    pattern: "The Marionette Collective version %{version} started by %{name} using config file %{config}"
  PLMC10:
    example: "Failed to handle message: RuntimeError: none.rb:15:in `decodemsg': Could not decrypt message "
    expanded: |-
        When a message arrives from the middleware it gets decoded, security validated and then dispatched to the agent code.

        There exist a number of errors that can happen here, some are handled specifically others will be logged by this "catch all" handler.

        Generally there should not be many messages logged here but we include a stack trace to assist with debugging these.

        The messages here do not tend to originate from your Agents unless they are syntax error related but more likely to be situations like security failures due to incorrect SSL keys and so forth

        Should you come across one that is a regular accorance in your logs please open a ticket including your backtrace and we will improve the handling of that situation
    pattern: "Failed to handle message: %{error}"
  PLMC11:
    example: "Cache expired on 'ddl' key 'agent/nrpe'"
    expanded: |-
        MCollective has an internal Cache used to speed up operations like parsing of DDL files.  The cache is also usable from the agents and other plugins you write.

        Each entry in the cache has an associated TTL or maximum life time, once the maximum time on an item is reached it is considered expired.  Next time anything attempts to read this entry from the cache this log line will be logged.

        This is part of the normal operations of MCollective and doesn't indicate any problem.  We log this debug message to help you debug your own use of the cache.
    pattern: "Cache expired on '%{cache_name}' key '%{item}'"
  PLMC12:
    example: "Cache hit on 'ddl' key 'agent/nrpe'"
    expanded: |-
        MCollective has an internal Cache used to speed up operations like parsing of DDL files.  The cache is also usable from the agents and other plugins you write.

        Each entry in the cache has an associated TTL or maximum life time, once the maximum time on an item is reached it is considered expired.

        This log line indicates that a request for a cache entry was made, the entry had not yet expired and so the cached data is being returned.

        It does not indicate a problem, it's just a debugging aid
    pattern: "Cache hit on '%{cache_name}' key '%{item}'"
  PLMC13:
    example: "Could not find a cache called 'my_cache'"
    expanded: |-
        MCollective has an internal Cache used to speed up operations like parsing of DDL files.  The cache is also usable from the agents and other plugins you write.

        The cache is made up of many named caches, this error indicates that a cache has not yet been setup prior to trying to use it.
    pattern: "Could not find a cache called '%{cache_name}'"
  PLMC14:
    example: "No block supplied to synchronize on cache 'my_cache'"
    expanded: |-
        When using the Cache to synchronize your own code across agents or other plugins you have to supply a block to synchronise.

        Correct usage would be:

            Cache.setup(:customer, 600)
            Cache(:customer).synchronize do
               # update customer record
            end

        This error is raise when the logic to update the customer record is not in a block as in the example
    pattern: "No block supplied to synchronize on cache '%{cache_name}'"
  PLMC15:
    example: "No item called 'nrpe_agent' for cache 'ddl'"
    expanded: |-
        MCollective has an internal Cache used to speed up operations like parsing of DDL files.  The cache is also usable from the agents and other plugins you write.

        The cache stored items using a key, this error will be logged and raised when you try to access a item that does not yet exist in the cache.
    pattern: "No item called '%{item}' for cache '%{cache_name}'"
  PLMC16:
    example: "'hello' does not look like a numeric value"
    expanded: |-
        When MCollective receives an argument from the command line like port=fello it consults the DDL file to determine the desired type of this parameter, it then tries to convert the input string into the correct numeric value.

        This error indicates the input you provided could not be converted into the desired format.

        You'll usually see this when using the 'mco rpc' command to interact with an agent.  This is usually a fatal error, the request will not be sent if it does not validate against the DDL.
    pattern: "'%{value}' does not look like a numeric value"
  PLMC17:
    example: "'flase' does not look like a boolean value"
    expanded: |-
        When MCollective receives an argument from the command line like force=true it consults the DDL file to determine the desired type of this parameter, it then tries to convert the input string into the correct boolean value.

        This error indicates the input you provided could not be converted into the desired boolean format.  It wil accept "true", "t", "yes", "y" and "1" as being true.  It will accept "false", "f", "no", "n", "0" as being false.

        You'll usually see this when using the 'mco rpc' command to interact with an agent.  This is usually a fatal error, the request will not be sent if it does not validate against the DDL.
    pattern: "'%{value}' does not look like a boolean value"
  PLMC18:
    example: "Found 'rpcutil' ddl at '/usr/libexec/mcollective/mcollective/agent/rpcutil.ddl'"
    expanded: |-
        Most plugin types have a DDL file that needs to be correctly installed for the plugin to function.  There can be multiple libdirs that can provide the DDL file for a specific plugin.

        This message is a message designed to help you debug issues when you think the wrong DDL file is being used.
    pattern: "Found '%{ddlname}' ddl at '%{ddlfile}'"
  PLMC19:
    expanded: |-
        Usually when MCollective run it validates all requirements are met before publishing a request or processing a request against the DDL file for the agent.

        This can be difficult to satisfy in development perhaps because you are still writing your DDL files or debugging issues.

        This message indicates that when MCollective detects it's running against an unreleased version of MCollective - like directly out of a Git clone - it will skip the DDL validation steps.  It is logged at a warning level as this significantly changes the behaviour of the client and server.
    pattern: "DDL requirements validation being skipped in development"
  PLMC2:
    expanded: "When sending the mcollectived process the USR1 signal on a Unix based machine this message will indicate that the signal got received and all agents are being reloaded from disk\n"
    pattern: "Reloading all agents after receiving USR1 signal"
  PLMC20:
    example: "Agent plugin 'example' requires MCollective version 2.2.1 or newer"
    expanded: |-
        MCollective plugins can declare a minimum version of MCollective that they require to be functional.

        MCollective validates this when it loads the plugin and this error will be logged or shown to the user when this requirement cannot be satisfied.
    pattern: "%{type} plugin '%{name}' requires MCollective version %{requirement} or newer"
  PLMC21:
    example: "Cannot validate input 'service': Input string is longer than 40 character(s)"
    expanded: |-
        Every input you provide to a RPC request is validated against it's DDL file. This error will be shown when the supplied data does not pass validation against the DDL.

        Consult the 'mco plugin doc' command to view the DDL file for your action and input.
    pattern: "Cannot validate input '%{input}: %{error}"
  PLMC22:
    example: "Cannot determine what entity input 'port' belongs to"
    expanded: |-
        When writing a DDL you declare inputs into plugins using the input keyword.  Each input has to belong to a wrapping entity like in the example below:

            action "get_data", :description => "Get data from a data plugin" do
                input :source,
                      :prompt      => "Data Source",
                      :description => "The data plugin to retrieve information from",
                      :type        => :string,
                      :validation  => '^\w+$',
                      :optional    => false,
                      :maxlength   => 50
            end

        Here the input belongs to the action entity "get_data", this error indicates that an input were found without it belonging to any specific entity
    pattern: "Cannot determine what entity input '%{input}' belongs to"
  PLMC23:
    example: "Input needs a :prompt property"
    expanded: "When writing a DDL you declare inputs for all data that you pass into the plugin.  Inputs have a minimally required field set and this error indicate that you did not provide some key field while describing the input."
    pattern: "Input needs a :%{property} property"
  PLMC24:
    example: "Failed to load DDL for the 'rpcutil' agent, DDLs are required: RuntimeError: failed to parse DDL file"
    expanded: |-
        As of version 2.0.0 DDL files are required by the MCollective server.  This server indicates that it either could not find the DDL for the rpcutil agent or that there was a syntax error.

        Confirm that the DDL file is installed in the agent directory and that it parses correctly using the 'mco plugin doc' command.
    pattern: "Failed to load DDL for the '%{agent}' agent, DDLs are required: %{error_class}: %{error}"
  PLMC25:
    example: "aggregate method for action 'rpcutil' is missing a function parameter"
    expanded: |-
        DDL files can declare aggregation rules for the data returned by actions as seen below:

                 summarize do
                    aggregate summary(:collectives)
                 end

        This error indicates that you did not supply the argument - :collectives in this example.
    pattern: "aggregate method for action '%{action}' is missing a function parameter"
  PLMC26:
    expanded: |-
        Internally when MCollective parse the DDL it converts the aggregate functions into a hash with the function name and any arguments.

        This error indicates that the internal translation failed, this is a critical error and would probably indicate a structure problem in your DDL or a bug in MCollective
    pattern: "Functions supplied to aggregate should be a hash"
  PLMC27:
    expanded: |-
        DDL aggregate functions can take a custom format as in the example below:

            aggregate average(:total_resources, :format => "Average: %d")

        This error indicate that the :format above could not be correctly parsed.
    pattern: "Formats supplied to aggregation functions must have a :format key"
  PLMC28:
    expanded: |-
        DDL aggregate functions can take a custom format as in the example below:

            aggregate average(:total_resources, :format => "Average: %d")

        This error indicate that the :format above was not supplied as a hash as in the above example
    pattern: "Formats supplied to aggregation functions should be a hash"
  PLMC29:
    example: "Attempted to call action 'yum_clean' for 'package' but it's not declared in the DDL"
    expanded: |-
        Every agent has a DDL file that describes valid actions that they can perform

        This error indicates you attempted to perform an action that does not exist.  Review the plugin documentation using 'mco plugin doc' for correct usage
    pattern: "Attempted to call action '%{action}' for '%{plugin}' but it's not declared in the DDL"
  PLMC3:
    expanded: |-
        When sending the mcollectived process the USR2 signal on a Unix based machine this message indicates that the signal for received and the logging level is being adjusted to the next higher level or back down to debug if it was already at it's highest level.

        This message will be followed by another message similar to the one below:

            Logging level is now WARN
    pattern: "Cycling logging level due to USR2 signal"
  PLMC30:
    example: "Action 'get_fact' needs a 'fact' argument"
    expanded: "Actions can declare that they expect a required input, this error indicates that you did not supply the required input"
    pattern: "Action '%{action}' needs a '%{key}' argument"
  PLMC31:
    example: "No dataquery has been defined in the DDL for data plugin 'package'"
    expanded: |-
        Each data plugin requires a DDL that has a 'dataquery' block in it.

            dataquery :description => "Agent Meta Data" do
                .
                .
            end

        This error indicates that the DDL file for a specific data plugin did not contain this block.
    pattern: "No dataquery has been defined in the DDL for data plugin '%{plugin}'"
  PLMC32:
    expanded: "Data plugins must return data.  The DDL files for a data plugin must declare at least one output parameter else you will see this error."
    pattern: "No output has been defined in the DDL for data plugin '%{plugin}'"
  PLMC33:
    example: "No data plugin argument was declared in the 'puppet' DDL but an input was supplied"
    expanded: |-
        Data plugins can take an optional input argument.  This error indicate that you supplied an input argument but the plugin does not actually expect any input.

        Review the documentation for the data plugin using 'mco plugin doc'
    pattern: "No data plugin argument was declared in the '%{plugin}' DDL but an input was supplied"
  PLMC34:
    example: "setting meta data in agents have been deprecated, DDL files are now being used for this information. Please update the 'package' agent"
    expanded: |-
        In the past each MCollective agent had a metadata section containing information like the timeout.

        As of 2.2.0 the agents will now consult the DDL files that ship with each agent for this purpose so the metadata in agents are not used at all.

        In order to remove confusing duplication setting metadata in agents have been deprecated and from version 2.4.0 will not be supported at all.

        Please update your agent by removing the metadata section from it and make sure the DDL file has the correct information instead.
    pattern: "setting meta data in agents have been deprecated, DDL files are now being used for this information. Please update the '%{agent}' agent"
  PLMC35:
    expanded: |-
        The MCollective client can ask that the agent just performs the action and never respond.  Like when supplying the --no-results option to the 'mco rpc' application.

        This log line indicates that the request was received and interpreted as such and no reply will be sent.  This does not indicate a problem generally it's just there to assist with debugging of problems.
    pattern: "Client did not request a response, surpressing reply"
  PLMC36:
    example: "Unknown action 'png' for agent 'rpcutil'"
    expanded: |-
        Agents are made up of a number of named actions.  When the MCollective Server receives a request it double checks if the agent in question actually implements the logic for a specific action.

        When it cannot find the implementation this error will be raised.  This is an unusual situation since at this point on both the client and the server the DDL will already have been used to validate the request and the DDL would have indicated that the action is valid.

        Check your agent code and make sure you have code like:

            action "the_action" do
                .
                .
            end
    pattern: "Unknown action '%{action}' for agent '%{agent}'"
  PLMC37:
    example: "Starting default activation checks for the 'rpcutil' agent"
    expanded: |-
        Each time the MCollective daemon starts it loads each agent from disk.  It then tries to determine if the agent should start on this node by using the activate_when method or per-agent configuration.

        This is a debug statement that shows you it is about to start interacting with the logic in the agent to determine if it should be made available or not.
    pattern: "Starting default activation checks for the '%{agent}' agent"
  PLMC38:
    example: "Found plugin configuration 'exim.activate_agent' with value 'y'"
    expanded: |-
        The administrator can choose that a certain agent that is deployed on this machine should not be made available to the network.

        To do this you would add a configuration value like this example to the mcollective server.cfg:

            plugin.exim.activate_agent = n

        If this value is "1", "y" or "true" the agent will be activated else it will be disabled.
    pattern: "Found plugin configuration '%{agent}.activate_agent' with value '%{should_activate}'"
  PLMC39:
    example: "Audit failed with an error, processing the request will continue."
    expanded: |-
        Every MCollective request can be audited.  In the event where the auditing fails the processing continues.

        At present the failure handling is not configurable, in future the administrator might elect to not run unaudited requests via configuration.
  PLMC4:
    example: "Failed to start registration plugin: ArgumentError: meta.rb:6:in `gsub': wrong number of arguments (0 for 2)"
    expanded: |
        Registration plugins are loaded into the MCollective daemon at startup and ran on a regular interval.

        This message indicate that on first start this plugin failed to run, it will show the exception class, line and exception message to assist with debugging
    pattern: "Failed to start registration plugin: %{error}"
  PLMC40:
    example: "Can't find DDL for agent plugin 'puppet'"
    expanded: |-
        MCollective plugins come with DDL files that describe their behaviours, versions, capabilities and requirements.

        This error indicate that a DDL file for the plugin mentioned could not be found - it could be that you have a typing error in your command line or an installation error.
    pattern: "Can't find DDL for %{type} plugin '%{name}'"
  PLMC41:
    example: "Data plugin 'agent()' function does not return a 'foo' value"
    expanded: |-
        Data functions return a set of values which can be identified by name.

        This message indicates that the specified value has not been defined in the Data plugin's DDL.
    pattern: "Data plugin '%{functionname}()' does not return a '%{value}' value"
  PLMC42:
    example: "Cannot convert string value 'hello' into a boolean. "
    expanded: |-
        This error gets logged when there is an attempt to convert a string value into a boolean, but the string does not match the boolean pattern.

        Strings that match "1", "y", "yes", "YES", "t", "true" and "TRUE" will be transformed into a boolean true.

        Strings that match "0", "n", "no", "NO", "f", "false" and "FALSE" will be transformed into a boolean false.
    pattern: "Cannot convert string value '%{value}' into a boolean. "
  PLMC5:
    expanded: |-
        In previous versions of MCollective a application called 'controller' were included that had the ability to request agent reloads and other commands that would control the runner.

        Unfortunately this method of controlling the daemon was never considered stable or reliable and has since been deprecate for removal during the 2.3.x development series
    pattern: "Received a control message, possibly via 'mco controller' but this has been deprecated"
  PLMC6:
    expanded: |-
        When a specific MCollective daemon receives a message from a network it validates the filter before processing the message.  The filter is the list of classes, facts or other conditions that are associated with any message.

        In the case where the filter does not match the specific host this line gets logged.

        It's often the case for broadcast messages that all MCollective nodes will receive a message but only a subset of nodes are targetted using the filters, in that situation the nodes that received the request but should not respond to it will see this log line.

        It does not indicate anything to be concerned about but if you find debugging a problem and expect a node to have responded when it shouldn't this log line will give you a hint that some condition specified in the filter did not match the local host
    pattern: "Message does not pass filters, ignoring"
  PLMC7:
    example: "Exiting after signal: SignalException: runner.rb:6:in `run': Interrupt"
    expanded: |-
        When the MCollective daemon gets a signal from the Operating System that it does not specifically handle it will log this line before exiting.

        You would see this whenever the daemon is stopped by init script or when sending it a kill signal, it will then proceed to disconnect from the middleware and exit its main loop
    pattern: "Exiting after signal: %{error}"
  PLMC8:
    example: "Handling message for agent 'rpcutil' on collective 'eu_collective' with requestid 'a8a78d0ff555c931f045b6f448129846'"
    expanded: |-
        After receiving a message from the middleware, decoding it, validating it's security credentials and doing other checks on it the MCollective daemon will pass it off to the actual agent code for processing.

        Prior to doing so it will log this line indicating the agent name and sub-collective and other information that will assist in correlating the message sent from the client with those in the server logs being processed.
    pattern: "Handling message for agent '%{agent}' on collective '%{collective} with requestid '%{requestid}'"
  PLMC9:
    example: "Expired Message: message 8b4fe522f0d0541dabe83ec10b7fa446 from cert=client@node created at 1358840888 is 653 seconds old, TTL is 60"
    expanded: |-
        Requests sent from clients to servers all have a creation time and a maximum validity time called a TTL.

        This message indicates that a message was received from the network but that it was determined to be too based on the TTL settings.

        Usually this happens because your clocks are not in sync - something that can be fixed by rolling out a tool like ntp across your server estate.

        It might also happen during very slow network conditions or when the TTL is set too low for your general network latency.
    pattern: "Expired Message: %{error}"
